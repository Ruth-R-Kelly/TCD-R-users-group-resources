library('GISTools')
library('RColorBrewer')
library('raster')
### read in your data file as from .csv or text file as usual.
## e.g.
all_sites_year1 <- read.csv("all_sites_year2.csv")
### view this to see if it has loaded properly
summary(all_sites_year1)
head(all_sites_year1)
class(all_sites_year1)
### Turn this into a SpatialPointsDataFrame,
## using the function ' coordinates'in the package 'sp'
## You do this by 'telling' R which columns in the dataframe contain the
## coordinate locations.
### The objects after the <- are the names of the columns containing the
### coordinate data in the dataframe.
### Don't forget the ~ symbol after the  <-
coordinates(all_sites_year1) <- ~ x_coordina + y_coordina
class(all_sites_year1)
## all_sites_year1 is now a spatial file, class = sp
### Note that when we plot this R automatically plots the coordinate columns.
plot(all_sites_year1, pch = 1)
counties <- readOGR(dsn = ".", layer = "ni_counties")
#### plot these
plot(counties)
plot(all_sites_year1, col = all_sites_year1$Burnt, pch = 16, add = T)
class(all_sites_year1)
### the dataset
head(all_sites_year1@data)
### the coordinate system
all_sites_year1@proj4string
### boundary box
all_sites_year1@bbox
# Read in the data - note this loads 4 objects
data(vulgaris)
class(vulgaris)
class(us_states)
### reset the margins to make plot bigger.
par(mar = c(0,0,2,0))
#### add colour
plot(us_states, col = "grey80")
### change background colour
plot(us_states, col = "grey80", bg = "light blue")
####  Add title
title("US states")
### Just set the argument add = T in the plot function.
## eg point data from vulgaris
plot(us_states, col = "grey80", bg = "light blue")
### You can change colours of points etc. by calling the columns in the dataset
### just like in base R
plot(vulgaris, pch = 16, col = vulgaris$Year, add = T)
##### Note: colours here are coming from the RColourBrewer package
### reset the margins to make plot bigger.
par(mar = c(3,2,2,0))
### set colours for your population plot data
cols1 <- auto.shading(us_states$POP1997, cols = brewer.pal(6,"Reds"))
### plot with test new colours..
choropleth(us_states, us_states$POP1997, shading = cols1)
### add legend
choro.legend(-128, 31, cols1, cex = 0.5)
alt1 <- readAsciiGrid("alt1_test.asc")
image(alt1@data, terrain.colors(100))
alt2 <- raster(alt1)
image(alt2, terrain.colors(100))
plot(alt1, col = terrain.colors)
image(round(alt2), terrain.colors(100))
plot(alt2)
plot(alt1)
plot(alt1,terrain.colors(100) )
plot(alt1@data,cols = terrain.colors(100) )
image(alt2)
image(alt2)
plot(alt2)
class(alt1)
alt2@bbox
alt1@proj4string
summary(alt1@data)
alt2@bbox
class(alt2)
head(alt2)
str(alt2)
alt2 <- raster(alt1)
class(alt2)
image(alt2)
plot(alt2)
alt1 <- readAsciiGrid("alt1_test.asc")
class(alt1)
#### Note that this is now a Spatial Grid dataframe and has similar attributes to the shapefiles above
# alt1@bbox
# alt1@proj4string
# summary(alt1@data)
### Make this a raster for plotting reasons
alt2 <- raster(alt1)
class(alt2)
### the most intuitive plotting is achieved
## image(alt2)
## Or simply
plot(alt2, yaxt = "n")
alt1 <- readAsciiGrid("alt1_test.asc")
class(alt1)
#### Note that this is now a Spatial Grid dataframe and has similar attributes to the shapefiles above
# alt1@bbox
# alt1@proj4string
# summary(alt1@data)
### Make this a raster for plotting reasons
alt2 <- raster(alt1)
class(alt2)
### the most intuitive plotting is achieved
## image(alt2)
## Or simply
plot(alt2, yaxt = "n", xaxt = "n")
alt1 <- readAsciiGrid("alt1_test.asc")
class(alt1)
#### Note that this is now a Spatial Grid dataframe and has similar attributes to the shapefiles above
# alt1@bbox
# alt1@proj4string
# summary(alt1@data)
### Make this a raster for plotting reasons
alt2 <- raster(alt1)
class(alt2)
### the most intuitive plotting is achieved
## image(alt2)
## Or simply
plot(alt2, yaxt = "n", xaxt = "n")
plot(all_sites_year1, add = T)
alt1 <- readAsciiGrid("alt1_test.asc")
class(alt1)
#### Note that this is now a Spatial Grid dataframe and has similar attributes to the shapefiles above
# alt1@bbox
# alt1@proj4string
# summary(alt1@data)
### Make this a raster for plotting reasons
alt2 <- raster(alt1)
class(alt2)
### the most intuitive plotting is achieved
## image(alt2)
## Or simply
plot(alt2, yaxt = "n", xaxt = "n")
plot(all_sites_year1, add = T, pch = 1)
?extract
sites_with_altitude <- extract(x = alt2, y = all_sites_year1, sp = TRUE)
names(sites_with_altitude)
all_sites_year1 <- read.csv("all_sites_year2.csv")
View(all_sites_year1)
coordinates(all_sites_year1) <- ~ x_coordina + y_coordina
library("maptools")
library("rgdal")
library("sp")
library('GISTools')
library('RColorBrewer')
library('raster')
### read in your data file as from .csv or text file as usual.
## e.g.
all_sites_year1 <- read.csv("all_sites_year2.csv")
### view this to see if it has loaded properly
summary(all_sites_year1)
head(all_sites_year1)
class(all_sites_year1)
### Turn this into a SpatialPointsDataFrame,
## using the function ' coordinates'in the package 'sp'
## You do this by 'telling' R which columns in the dataframe contain the
## coordinate locations.
### The objects after the <- are the names of the columns containing the
### coordinate data in the dataframe.
### Don't forget the ~ symbol after the  <-
coordinates(all_sites_year1) <- ~ x_coordina + y_coordina
class(all_sites_year1)
## all_sites_year1 is now a spatial file, class = sp
### Note that when we plot this R automatically plots the coordinate columns.
plot(all_sites_year1, pch = 1)
counties <- readOGR(dsn = ".", layer = "ni_counties")
#### plot these
plot(counties)
plot(all_sites_year1, col = all_sites_year1$Burnt, pch = 16, add = T)
str(counties)
head(all_sites_year1@data)
all_sites_year1@proj4string
all_sites_year1@bbox
# Read in the data - note this loads 4 objects
data(vulgaris)
class(vulgaris)
class(us_states)
### reset the margins to make plot bigger.
par(mar = c(0,0,2,0))
#### add colour
plot(us_states, col = "grey80")
### change background colour
plot(us_states, col = "grey80", bg = "light blue")
####  Add title
title("US states")
### Just set the argument add = T in the plot function.
## eg point data from vulgaris
plot(us_states, col = "grey80", bg = "light blue")
### You can change colours of points etc. by calling the columns in the dataset
### just like in base R
plot(vulgaris, pch = 16, col = vulgaris$Year, add = T)
##### Note: colours here are coming from the RColourBrewer package
### reset the margins to make plot bigger.
par(mar = c(3,2,2,0))
### set colours for your population plot data
cols1 <- auto.shading(us_states$POP1997, cols = brewer.pal(6,"Reds"))
### plot with test new colours..
choropleth(us_states, us_states$POP1997, shading = cols1)
### add legend
choro.legend(-128, 31, cols1, cex = 0.5)
##### Note: colours here are coming from the RColourBrewer package
### reset the margins to make plot bigger.
par(mar = c(3,2,2,0))
### set colours for your population plot data
cols1 <- auto.shading(us_states$POP1997, cols = brewer.pal(8,"Reds"))
### plot with test new colours..
choropleth(us_states, us_states$POP1997, shading = cols1)
### add legend
choro.legend(-128, 31, cols1, cex = 0.5)
alt1 <- readAsciiGrid("alt1_test.asc")
class(alt1)
#### Note that this is now a Spatial Grid dataframe and has similar attributes to the shapefiles above
# alt1@bbox
# alt1@proj4string
# summary(alt1@data)
### Make this a raster for plotting reasons
alt2 <- raster(alt1)
class(alt2)
### the most intuitive plotting is achieved
## image(alt2)
## Or simply
plot(alt2, yaxt = "n", xaxt = "n")
# to add points..
#plot(all_sites_year1, add = T, pch = 16)
### Hint the function extract in the package raster takes the values from a raster file
### and adds them to points in another file.
#sites_with_altitude <- extract(x = alt2, y = all_sites_year1, sp = TRUE)
#names(sites_with_altitude)
alt1@proj4string
counties@proj4string
alt1@proj4string <- counties@proj4string
?CRS()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library("car")  ## for calculating Anova tables
library("multcomp") ## for doing post-hoc tests
library("lme4")
### for a simple example load the dataset iris
data(iris)
### this dataset contains information on morphological attributes of three species of iris.  A summary of the data is provided by.
summary(iris)
plot(iris)
names(iris)
### choose a single species for a first simple model eg.
setosa1 <- iris[iris$Species == "setosa",]
setosa1 <- droplevels(setosa1)
####
model1 <- lm(Petal.Length ~ Petal.Width, data = setosa1)
plot(Petal.Length ~ Petal.Width, setosa1)
abline(model1, col='red') #plots lm line, slope and intercept can be found in summary
# Model validation
# Are residuals normally distributed?
## To visualize
hist(residuals(model1))
qqnorm(residuals(model1))
qqline(residuals(model1))
### to formally test this examine you may use shapiro.test (there are many options), ## P > 0.05 indicates distribution is not significantly different from normal.
shapiro.test(residuals(model1))
# 	Shapiro-Wilk normality test
#
# data:  residuals(model1)
# W = 0.97916, p-value = 0.517
####
# Homegeneity of variance
## plot residuals against predictor variables. Here you should see no pattern
plot(residuals(model1) ~ setosa1$Petal.Width)
## The model can be easily expanded to add more variables using "+" or "*" for interactions
#e.g.
model2 <- lm(Petal.Length ~ Petal.Width + Species, data = iris) ## etc
######
### load dataset
chem <- read.csv("chem_example.csv")
##### This dataset contains data on soil chemistry for quadrats within 6 sites.
##### The variable of interest is burning, in particular it's effect on soil chemistry
names(chem)
str(chem)
summary(chem)
#### Let's look at P - Phosphorus
summary(chem$P)
### Note all positive and continous
hist(chem$P, breaks = 20)
#### an optimist fits a normal model first..
mod_norm <- glm(P~Burnt*Habitat + Site, data = chem)
hist(residuals(mod_norm))
shapiro.test(residuals(mod_norm))
# Shapiro-Wilk normality test
#
# data:  residuals(mod_norm)
# W = 0.9391, p-value = 3.212e-05
##### not normal...
plot(mod_norm)
##### Try a gamma distribution with a log link
mod_log <- glm(P~Burnt*Habitat + Site, data = chem, family = "Gamma"(link = "log"))
plot(mod_log)
res1 <- residuals(mod_log, type = "deviance")
setwd("C:/R/TCD-R-users-group-resources/LM_GLM_M_overview")
### load dataset
chem <- read.csv("chem_example.csv")
##### This dataset contains data on soil chemistry for quadrats within 6 sites.
##### The variable of interest is burning, in particular it's effect on soil chemistry
names(chem)
str(chem)
summary(chem)
#### Let's look at P - Phosphorus
summary(chem$P)
### Note all positive and continous
hist(chem$P, breaks = 20)
#### an optimist fits a normal model first..
mod_norm <- glm(P~Burnt*Habitat + Site, data = chem)
hist(residuals(mod_norm))
shapiro.test(residuals(mod_norm))
# Shapiro-Wilk normality test
#
# data:  residuals(mod_norm)
# W = 0.9391, p-value = 3.212e-05
##### not normal...
plot(mod_norm)
mod_log <- glm(P~Burnt*Habitat + Site, data = chem, family = "Gamma"(link = "log"))
plot(mod_log)
chem <- read.csv("chem_example.csv")
##### This dataset contains data on soil chemistry for quadrats within 6 sites.
##### The variable of interest is burning, in particular it's effect on soil chemistry
names(chem)
str(chem)
summary(chem)
#### Let's look at P - Phosphorus
summary(chem$P)
### Note all positive and continous
hist(chem$P, breaks = 20)
#### an optimist fits a normal model first..
mod_norm <- glm(P~Burnt*Habitat + Site, data = chem)
hist(residuals(mod_norm))
shapiro.test(residuals(mod_norm))
# Shapiro-Wilk normality test
#
# data:  residuals(mod_norm)
# W = 0.9391, p-value = 3.212e-05
##### not normal...
plot(mod_norm)
mod_log <- glm(P~Burnt*Habitat + Site, data = chem, family = "Gamma"(link = "log"))
plot(mod_log)
AAR <- read.table("RoadKills.txt", header = T)
str(AAR)
names(AAR)
summary(AAR)
hist(AAR$TOT.N)
class(AAR$TOT.N)
summary(AAR$TOT.N)
mod_ARR <- glm(TOT.N ~ D.PARK, data = AAR, family = "poisson"(link = "log"))
summary(mod_ARR)
theta <- mod_ARR$deviance/mod_ARR$df.residual
theta
390.9/50
setwd("C:/R/TCD-R-users-group-resources/RClub_DIY_automated_plotting-master")
load("rclub.RData")
library(lme4)
library(AICcmodavg) # this has the predictSE function that we'll use
summary(top.step2)
head(coloniseSc,2)
head(coloniseSc_sample,2); dim(coloniseSc_sample)
m1<-glmer(pr ~ yr*lifespan + (1 + NO3soil | sp) + (1 | plot/plsub), data=coloniseSc, family=binomial)
summary(m1)
m1<-glmer(pr ~ yr*lifespan + (1 + NO3soil | sp) + (1 | plot/plsub), data=coloniseSc, family=binomial)
summary(m1)
m1<-glmer(pr ~ yr*lifespan + (1 + NO3soil | sp) + (1 | plot/plsub), data=coloniseSc, family=binomial)
nd1<-data.frame(yr=seq(0,20,1),lifespan=rep(c("A","P"),each=21))
pr1<-predictSE(m1,newdata=nd1,type="response")
res1<-data.frame(nd1,fit=pr1$fit,se=pr1$se.fit,lci=pr1$fit-(pr1$se.fit*1.98),uci=pr1$fit+(pr1$se.fit*1.98))
dev.new(title="",width=8,height=8, dpi=80, pointsize=18)
par(mar=c(5,5,1,1))
plot(res1$yr[res1$lifespan=="A"], res1$fit[res1$lifespan=="A"],type="l",lty=1, ylim=c(0, 1), xlab="Year", ylab="Probability of colonisation")
lines(res1$yr[res1$lifespan=="P"], res1$fit[res1$lifespan=="P"],lty=2)
pg.ci("yr","res1","lifespan",col=rgb(0,0,0,0.15))
legend("topleft",legend=c("Annual","Perennial"),lty=c(1,2))
summary(m1)$coefficients
all_years<-unique(coloniseSc$yr)
summary(m1)$coefficients
ests<-summary(m1)$coefficients[,1]
ests
iv1<-function(x) 1/(1 + exp(-x))
iv2<-function(x) exp(x)/(1+exp(x))
iv1(ests[1])
iv2(ests[1])
# to get estimates on the "response" scale, predict backtransforms estimates, depending on the type of model used, e.g. binomial (logit), poisson (log), gaussian (normal)
# our model is binomial, so we'll use the inverse of the logit function:
# inverse logit function for binomial models:
# logit() == log(x/(1 - x))
iv1<-function(x) 1/(1 + exp(-x))
iv2<-function(x) exp(x)/(1+exp(x))
# check:
iv1(ests[1])
iv2(ests[1])
# do the calculations:
# year zero, perennial:
iv1(ests[1])
# year one, perennial:
iv1(ests[1] + ests[2])
# year two, perennial:
iv1(ests[1] + (ests[2]*2))
# year fifteen, perennial:
iv1(ests[1] + (ests[2]*15))
# all years, perennial:
iv1(ests[1] + (ests[2]*seq(0,20,1)))
# make sure they're the same as what we found with predict:
res1$fit[res1$lifespan=="P"]
# do the same for annual
ests
# annual, year zero:
iv1(ests[1] + ests[3])
# annual, year one
iv1(ests[1] + ests[2] + ests[3] + ests[4])
# annual, year 15, etc:
iv1(ests[1] + (ests[2]*15) + ests[3] + (ests[4]*15))
# all years, annual:
iv1(ests[1] + (ests[2]*seq(0,20,1)) + ests[3] + (ests[4]*seq(0,20,1)))
# make sure they're the same as what we found with predict:
res1$fit[res1$lifespan=="A"]
# ------------------------------->
# --- ESTIMATES FROM THE BIG MODEL:
# now that we can use predict with confidence, we can automate plotting from the big model....
# The enormous plant invader model:
summary(top.step2)
coef.ext
CItrans
coef.sum
head(step2_top_coef)
nd.s3
coef.ext
CItrans
coef.sum
head(step2_top_coef)
nd.s3
estimates.nd
# The arguments are: the model, the xaxis.term, the data scaled and the data unscaled
# The estimates are stored as objects for each term, and can be accessed by the name in the nd.s3 table. You could also store them as a list or however you prefer.
# (uses full data set, so will not run, but it is save in workspace):
for (i in 1:length(nd.s3[,1])){
if (nd.s3$interaction[i]=="main"){
assign(nd.s3$df.name[i],estimates.nd("top.step2",xaxis.term=nd.s3$xaxis.term[i],modelled.data="coloniseSc",unscaled.data="col.unscaled"))
} # close if main
if (nd.s3$interaction[i]=="int"){
assign(nd.s3$df.name[i],estimates.nd("top.step2", xaxis.term=nd.s3$xaxis.term[i],int.term=nd.s3$int.term[i],modelled.data="coloniseSc",unscaled.data="col.unscaled"))
} # close if interaction
} # close i for data frame loop
# ------------------------------->
# --- PLOT:
# The plot code will use a hand-made table, based on nd.s3 above, but with columns added for the axis labels. These have been formatted exactly as I want them to appear on the plots. It contains all of the terms in the model that were significant. These are the ones we want to plot:
step2.plot2
# As we saw in the section above, the estimates for each term were stored as objects named in the 'data' column of the table, e.g:
head(get(as.character(step2.plot2$data[1])))
# The code will use the pg.ci function that I wrote to plot the CIs as polygons
pg.ci
# But other than that, the rest is really simple base code; the axes are already formatted in the table above
# This is mac code, so might not look pretty in R Studio or other platforms. I have included a PDF in the zip folder so you can see what it should look like
dev.new(title="",width=11.69,height=8.27, dpi=64, pointsize=19)
par(mfrow=c(3,4),mar=c(4,4,1.5,1), pch=20, las=1, bty="l", mgp=c(2.7,1,0),oma=c(0,0,1,0))
for (i in 1:length(step2.plot2[,1])){
data.thisrun<-get(as.character(step2.plot2$data[i]))
plot.x<-data.thisrun[,as.character(step2.plot2$x.variable[i])]
plot.y<-data.thisrun[,"fit"]
plot(plot.x, plot.y, type="n", ylab="Invader occupancy", xlab="", ylim=c(0,1))
if(step2.plot2$x.label[i]=="Soil NO3") title(xlab=expression(paste("Soil ", NO[3]),mgp=c(2.2,1,0))) else title(xlab=as.character(step2.plot2$x.label[i]),mgp=c(2.2,1,0))
if (step2.plot2$interaction[i]=="main"){
pg.ci(as.character(step2.plot2$x.variable[i]),as.character(step2.plot2$data[i]),colour=rgb(0,0,0,0.1))
lines(plot.x, plot.y)
} # close if main
if (step2.plot2$interaction[i]=="int"){
pg.ci(as.character(step2.plot2$x.variable[i]),as.character(step2.plot2$data[i]),x.subset=as.character(step2.plot2$x.subset[i]),colour=rgb(0,0,0,0.1))
sub1<-unique(data.thisrun[,as.character(step2.plot2$x.subset[i])])[1]
sub2<-unique(data.thisrun[,as.character(step2.plot2$x.subset[i])])[2]
linex.lev1<-data.thisrun[,as.character(step2.plot2$x.variable[i])][data.thisrun[,as.character(step2.plot2$x.subset[i])]==sub1]
liney.lev1<-data.thisrun$fit[data.thisrun[,as.character(step2.plot2$x.subset[i])]==sub1]
lines(linex.lev1, liney.lev1, lty=1)
linex.lev2<-data.thisrun[,as.character(step2.plot2$x.variable[i])][data.thisrun[,as.character(step2.plot2$x.subset[i])]==sub2]
liney.lev2<-data.thisrun$fit[data.thisrun[,as.character(step2.plot2$x.subset[i])]==sub2]
lines(linex.lev2, liney.lev2, lty=2)
par(xpd=NA)
legend(par("usr")[1],1.1,legend=c(as.character(step2.plot2$x1.label[i]),as.character(step2.plot2$x2.label[i])),lty=c(1,2),bty="n")
par(xpd=F)
} # close if interaction
par(xpd=NA)
text(par("usr")[1],par("usr")[4]+0.15,paste("(",letters[i],")",sep=""),cex=1.2)
par(xpd=F)
} # close plot for
# ------------------------------->
# --- MORE INTERACTIONS:
head(st1sc,2) # data, predictors scaled
head(st1,2) # data unscaled
gdmod<-lm(ar_adapt~st*native, data=st1sc)
summary(gdmod); nobs(gdmod)
# model estimates:
head(st.ests); dim(st.ests)
# coefficients:
st.coef
dev.new(title="",width=7,height=7, dpi=80, pointsize=18)
par(mfrow=c(1,1),mgp=c(3.5,1,0),mar=c(5,5,1,1))
plot(st.ests$pred.data[st.ests$native=="native"],st.ests$fit[st.ests$native=="native"], type="l", ylim=c(min(c(st.ests$lci,st1sc$ar_adapt)),max(c(st.ests$uci,st1sc$ar_adapt))),las=1, ylab="Genetic diversity", xlab="",xaxt="n")
lines(st.ests$pred.data[st.ests$native=="non_native"],st.ests$fit[st.ests$native=="non_native"],lty=2)
xax<-seq(round(min(st1sc[,"st"]),0),round(max(st1sc[,"st"]),0),length.out=5)
xaxl<-round(seq(round(min(st1[,"st"]),0),round(max(st1[,"st"]),0),length.out=5),0)
axis(side=1, at=xax, labels=xaxl)
title(xlab="Temperature seasonality",mgp=c(2.7,1,0))
pg.ci("pred.data","st.ests",x.subset="native",colour=rgb(0,0,0,0.1))
points(st1sc[st1sc$native=="native","st"],st1sc[st1sc$native=="native","ar_adapt"],col="black",pch=20)
points(st1sc[st1sc$native=="non_native","st"],st1sc[st1sc$native=="non_native","ar_adapt"],col="red", pch=20)
legend("bottomright",legend=c("native","non native"),lty=c(1,2))
legend("bottomright",legend=c("",""),pch=20, col=c("black","red"),bty="n",inset=c(0.26,0))
